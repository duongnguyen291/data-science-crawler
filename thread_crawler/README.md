# Sentiment Analysis on Social Media Comments via Web Crawling

Dá»± Ã¡n phÃ¢n tÃ­ch cáº£m xÃºc (sentiment analysis) trÃªn comments tá»« cÃ¡c ná»n táº£ng máº¡ng xÃ£ há»™i thÃ´ng qua web crawling.

## ğŸ¯ Má»¥c tiÃªu dá»± Ã¡n

- Crawl comments tá»« cÃ¡c ná»n táº£ng máº¡ng xÃ£ há»™i (YouTube, Facebook, TikTok, Instagram)
- Tá»± Ä‘á»™ng phÃ¢n loáº¡i cáº£m xÃºc: positive, negative, neutral
- Tá»•ng há»£p káº¿t quáº£ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ pháº£n á»©ng cÃ´ng chÃºng

## ğŸ“‹ TÃ­nh nÄƒng hiá»‡n táº¡i

### âœ… ÄÃ£ hoÃ n thÃ nh
- [x] **YouTube Comment Crawler** - Sá»­ dá»¥ng YouTube Data API v3
- [x] **Threads Scraper** - Crawl dá»¯ liá»‡u tá»« Threads by Meta (NEW! ğŸ‰)
  - Scrape thread (post) vá»›i replies
  - Scrape profile vá»›i threads gáº§n Ä‘Ã¢y
  - So sÃ¡nh nhiá»u users
  - PhÃ¢n tÃ­ch engagement chi tiáº¿t
  - Export JSON/CSV/Excel
- [x] **Twitter Entertainment Crawler** - Sá»­ dá»¥ng snscrape (NEW! ğŸ”¥)
  - Scrape tweets vá» films vÃ  music
  - Chá»‰ láº¥y English tweets
  - Tá»± Ä‘á»™ng phÃ¢n loáº¡i film/music
  - Extract engagement metrics (likes, retweets, replies)
  - Filter by date range, keywords, users
  - TÃ­ch há»£p data cleaning
  - Export CSV/JSON
- [x] **Top Comments Feature** - Láº¥y comments cÃ³ lÆ°á»£t like cao nháº¥t
- [x] **Multiple Ordering Options** - Sáº¯p xáº¿p theo thá»i gian, relevance
- [x] **Data Schema** - Cáº¥u trÃºc dá»¯ liá»‡u chuáº©n hÃ³a
- [x] **Data Cleaning** - LÃ m sáº¡ch vÃ  chuáº©n hÃ³a dá»¯ liá»‡u
- [x] **Language Detection** - PhÃ¡t hiá»‡n ngÃ´n ngá»¯ (Tiáº¿ng Viá»‡t/Tiáº¿ng Anh)
- [x] **Export Data** - Xuáº¥t dá»¯ liá»‡u CSV/JSON/Excel

### ğŸš§ Äang phÃ¡t triá»ƒn
- [ ] **Sentiment Analysis Models** - PhoBERT, BERT, etc.
- [ ] **Visualization Dashboard** - Streamlit/Flask
- [ ] **Multi-platform Support** - Facebook, TikTok, Instagram (Threads âœ…)
- [ ] **Database Integration** - SQLite/PostgreSQL

## ğŸš€ CÃ i Ä‘áº·t

### 1. Clone repository
```bash
git clone <repository-url>
cd data-science-crawler
```

### 2. Chá»n Python Version

âš ï¸ **Quan trá»ng**: `snscrape` yÃªu cáº§u **Python 3.11 hoáº·c tháº¥p hÆ¡n** (khÃ´ng tÆ°Æ¡ng thÃ­ch Python 3.12+)

#### **Option A: Sá»­ dá»¥ng Python 3.11 (Khuyáº¿n nghá»‹)**

```bash
# Kiá»ƒm tra Python 3.11 cÃ³ sáºµn khÃ´ng
python3.11 --version

# Náº¿u chÆ°a cÃ³, cÃ i Python 3.11:
# macOS (Homebrew):
brew install python@3.11

# Ubuntu/Debian:
sudo apt-get install python3.11 python3.11-venv python3.11-dev

# Sau Ä‘Ã³ cháº¡y setup vá»›i Python 3.11:
bash setup_py311.sh
```

#### **Option B: Sá»­ dá»¥ng Python 3.12+ vá»›i Fork**

Náº¿u muá»‘n dÃ¹ng Python 3.12+, cáº§n dÃ¹ng fork cá»§a snscrape:

```bash
pip install git+https://github.com/JustAnotherArchivist/snscrape.git
```

### 3. CÃ i Ä‘áº·t uv (náº¿u chÆ°a cÃ³)

**uv** lÃ  package manager Python nhanh, Ä‘Æ°á»£c viáº¿t báº±ng Rust (optional nhÆ°ng khuyáº¿n nghá»‹).

```bash
# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Hoáº·c dÃ¹ng pip
pip install uv

# Hoáº·c dÃ¹ng pipx
pipx install uv

# Hoáº·c dÃ¹ng homebrew (macOS)
brew install uv
```

### 4. Táº¡o virtual environment vÃ  cÃ i dependencies

#### CÃ¡ch 1: Sá»­ dá»¥ng setup script vá»›i Python 3.11 (Khuyáº¿n nghá»‹ cho snscrape)

```bash
# macOS/Linux - Python 3.11
bash setup_py311.sh

# Hoáº·c setup thÃ´ng thÆ°á»ng (sáº½ dÃ¹ng Python hiá»‡n táº¡i)
bash setup.sh

# Windows PowerShell
.\setup.ps1

# Windows CMD
setup.bat
```

#### CÃ¡ch 2: Manual setup vá»›i Python 3.11

```bash
# Táº¡o virtual environment vá»›i Python 3.11
python3.11 -m venv .venv

# Hoáº·c dÃ¹ng uv (náº¿u cÃ³):
uv venv --python python3.11

# Activate virtual environment
# macOS/Linux:
source .venv/bin/activate

# Windows:
# PowerShell: .\.venv\Scripts\Activate.ps1
# CMD: .venv\Scripts\activate.bat

# Verify Python version (should show 3.11.x)
python --version

# CÃ i dependencies
# Vá»›i uv (nhanh hÆ¡n):
uv pip install -r requirements.txt

# Hoáº·c vá»›i pip:
pip install --upgrade pip
pip install -r requirements.txt
```

#### CÃ¡ch 3: DÃ¹ng pip (cháº­m hÆ¡n)

```bash
python -m venv .venv
source .venv/bin/activate  # macOS/Linux
# hoáº·c .venv\Scripts\activate  # Windows

pip install -r requirements.txt
```

### 5. CÃ i Ä‘áº·t Playwright browser (cho Threads scraper)

```bash
playwright install chromium
```

### 5. Thiáº¿t láº­p YouTube API Key

#### BÆ°á»›c 1: Táº¡o Google Cloud Project
1. Truy cáº­p [Google Cloud Console](https://console.cloud.google.com/)
2. Táº¡o project má»›i
3. Báº­t "YouTube Data API v3"
4. Táº¡o API Key

#### BÆ°á»›c 2: Cáº¥u hÃ¬nh API Key
```python
# Trong file youtube_crawler.py hoáº·c test_crawler.py
API_KEY = "YOUR_API_KEY_HERE"  # Thay tháº¿ báº±ng API key thá»±c
```

## ğŸ“– HÆ°á»›ng dáº«n sá»­ dá»¥ng

### 1. Sá»­ dá»¥ng cháº¿ Ä‘á»™ tÆ°Æ¡ng tÃ¡c (Khuyáº¿n nghá»‹)

```bash
python main.py
```

ChÆ°Æ¡ng trÃ¬nh sáº½ hÆ°á»›ng dáº«n báº¡n tá»«ng bÆ°á»›c:
- Nháº­p YouTube API Key
- Nháº­p URL video YouTube
- Chá»n cÃ¡c tÃ¹y chá»n (sá»‘ lÆ°á»£ng comments, thá»© tá»± sáº¯p xáº¿p, v.v.)
- Tá»± Ä‘á»™ng crawl, lÃ m sáº¡ch vÃ  lÆ°u dá»¯ liá»‡u

### 2. Sá»­ dá»¥ng command line

```bash
# Crawl comments cÆ¡ báº£n
python main.py --api-key YOUR_API_KEY --video-url "https://www.youtube.com/watch?v=dQw4w9WgXcQ"

# Crawl top comments cÃ³ lÆ°á»£t like cao
python main.py --api-key YOUR_API_KEY --video-url "https://www.youtube.com/watch?v=dQw4w9WgXcQ" --min-likes 10 --max-comments 50

# Crawl comments theo relevance
python main.py --api-key YOUR_API_KEY --video-url "https://www.youtube.com/watch?v=dQw4w9WgXcQ" --order relevance

# KhÃ´ng lÃ m sáº¡ch dá»¯ liá»‡u
python main.py --api-key YOUR_API_KEY --video-url "https://www.youtube.com/watch?v=dQw4w9WgXcQ" --no-clean

# KhÃ´ng lÆ°u káº¿t quáº£
python main.py --api-key YOUR_API_KEY --video-url "https://www.youtube.com/watch?v=dQw4w9WgXcQ" --no-save
```

### 3. Sá»­ dá»¥ng trong code Python

```python
from main import YouTubeCommentAnalyzer

# Khá»Ÿi táº¡o analyzer
analyzer = YouTubeCommentAnalyzer("YOUR_API_KEY")

# PhÃ¢n tÃ­ch comments
result = analyzer.analyze_comments(
    video_url="https://www.youtube.com/watch?v=dQw4w9WgXcQ",
    max_comments=100,
    order='time',
    min_likes=0,
    clean_data=True,
    save_results=True
)

if result['success']:
    print(f"Crawled {result['total_comments']} comments")
    print(f"Saved files: {result['saved_files']}")
```

### 4. Test cÃ¡c module riÃªng láº»

```bash
# Test data cleaner
python data_cleaner.py

# Test logger configuration
python logger_config.py
```

## ğŸ“Š Cáº¥u trÃºc dá»¯ liá»‡u

### Schema Comments
```python
{
    'comment_id': 'VARCHAR(255)',      # ID gá»‘c tá»« YouTube
    'post_id': 'VARCHAR(255)',         # Video ID
    'platform': 'VARCHAR(50)',         # "YouTube", "Facebook", etc.
    'author_name': 'TEXT',             # TÃªn ngÆ°á»i bÃ¬nh luáº­n
    'author_id': 'VARCHAR(255)',       # Channel ID
    'comment_text': 'TEXT',            # Ná»™i dung comment
    'published_at': 'TIMESTAMP',       # Thá»i gian Ä‘Äƒng
    'like_count': 'INTEGER',           # Sá»‘ lÆ°á»£t thÃ­ch
    'reply_count': 'INTEGER',          # Sá»‘ lÆ°á»£t tráº£ lá»i
    'sentiment_label': 'VARCHAR(20)',  # positive/negative/neutral
    'sentiment_score': 'FLOAT',        # Äiá»ƒm tin cáº­y (0-1)
    'crawled_at': 'TIMESTAMP',         # Thá»i Ä‘iá»ƒm crawl
    'is_reply': 'BOOLEAN',             # CÃ³ pháº£i reply khÃ´ng
    'parent_comment_id': 'VARCHAR(255)' # ID comment gá»‘c
}
```

### Dá»¯ liá»‡u sau khi lÃ m sáº¡ch
```python
{
    'comment_text_clean': 'TEXT',      # Text Ä‘Ã£ lÃ m sáº¡ch
    'language': 'VARCHAR(10)',         # 'vi' hoáº·c 'en'
    'text_length': 'INTEGER',          # Äá»™ dÃ i text
    'word_count': 'INTEGER',           # Sá»‘ tá»«
    'is_valid': 'BOOLEAN',             # Comment há»£p lá»‡
    'cleaned_at': 'TIMESTAMP'          # Thá»i Ä‘iá»ƒm lÃ m sáº¡ch
}
```

## ğŸ”§ Cáº¥u hÃ¬nh

### YouTube API Quota
- **Miá»…n phÃ­**: 10,000 units/ngÃ y
- **1 request láº¥y comments**: ~1 unit
- **Khuyáº¿n nghá»‹**: KhÃ´ng crawl quÃ¡ 1000 comments/video

### Crawler Settings
```python
CRAWLER_CONFIG = {
    "max_comments_per_video": 1000,
    "max_replies_per_comment": 10,
    "delay_between_requests": 1,  # giÃ¢y
    "retry_attempts": 3,
}
```

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
DataScience/
â”œâ”€â”€ main.py                # File chÃ­nh - tá»•ng há»£p táº¥t cáº£ chá»©c nÄƒng
â”œâ”€â”€ youtube_crawler.py     # YouTube comment crawler
â”œâ”€â”€ data_cleaner.py        # Data cleaning utilities
â”œâ”€â”€ logger_config.py       # Logging configuration
â”œâ”€â”€ config.py             # Configuration settings
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ README.md            # HÆ°á»›ng dáº«n nÃ y
â””â”€â”€ logs/                # Log files (tá»± táº¡o)
    â”œâ”€â”€ youtube_crawler.log
    â”œâ”€â”€ data_cleaner.log
    â”œâ”€â”€ main.log
    â””â”€â”€ test.log
```

## ğŸš¨ LÆ°u Ã½ quan trá»ng

### YouTube API
- âœ… **á»”n Ä‘á»‹nh**: Sá»­ dá»¥ng API chÃ­nh thá»©c
- âœ… **Há»£p phÃ¡p**: ÄÆ°á»£c YouTube cho phÃ©p
- âš ï¸ **Giá»›i háº¡n**: CÃ³ quota limit
- âš ï¸ **Chi phÃ­**: CÃ³ thá»ƒ phÃ¡t sinh phÃ­ náº¿u vÆ°á»£t quota

### CÃ¡c ná»n táº£ng khÃ¡c
- âŒ **Facebook/Instagram**: Cáº§n App Review, ráº¥t khÃ³
- âŒ **TikTok**: KhÃ´ng cÃ³ API cÃ´ng khai
- âŒ **Threads**: KhÃ´ng cÃ³ API

### Khuyáº¿n nghá»‹
1. **Báº¯t Ä‘áº§u vá»›i YouTube** - Dá»… nháº¥t vÃ  á»•n Ä‘á»‹nh
2. **Test vá»›i Ã­t comments trÆ°á»›c** - TrÃ¡nh háº¿t quota
3. **LÆ°u trá»¯ dá»¯ liá»‡u** - TrÃ¡nh crawl láº¡i
4. **Monitor logs** - Theo dÃµi lá»—i vÃ  quota

## ğŸ› Troubleshooting

### Lá»—i thÆ°á»ng gáº·p

#### 1. API Quota Exceeded
```
Error: API quota exceeded
```
**Giáº£i phÃ¡p**: Äá»£i 24h hoáº·c nÃ¢ng cáº¥p quota

#### 2. Video Not Found
```
Error: Video not found
```
**Giáº£i phÃ¡p**: Kiá»ƒm tra URL video cÃ³ Ä‘Ãºng khÃ´ng

#### 3. Invalid API Key
```
Error: Invalid API key
```
**Giáº£i phÃ¡p**: Kiá»ƒm tra API key trong Google Cloud Console

### Debug Mode
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

## ğŸ“ˆ Káº¿ hoáº¡ch phÃ¡t triá»ƒn

### Phase 1: YouTube Crawler âœ…
- [x] Basic YouTube comment crawling
- [x] Top comments with highest likes
- [x] Multiple ordering options (time, relevance)
- [x] Data cleaning and validation
- [x] Export to CSV/JSON
- [x] Unified main.py interface

### Phase 2: Sentiment Analysis ğŸš§
- [ ] PhoBERT integration for Vietnamese
- [ ] BERT/DistilBERT for English
- [ ] Batch processing
- [ ] Confidence scoring

### Phase 3: Visualization ğŸ“Š
- [ ] Streamlit dashboard
- [ ] Real-time sentiment monitoring
- [ ] Export reports

### Phase 4: Multi-platform ğŸŒ
- [ ] Facebook Graph API integration
- [ ] TikTok unofficial API
- [ ] Instagram Basic Display API

## ğŸ¤ ÄÃ³ng gÃ³p

1. Fork repository
2. Táº¡o feature branch
3. Commit changes
4. Push to branch
5. Táº¡o Pull Request

## ğŸ§µ Threads Scraper - NEW!

### CÃ i Ä‘áº·t nhanh
```bash
# CÃ i Ä‘áº·t thÆ° viá»‡n
pip install playwright jmespath nested-lookup parsel pandas openpyxl

# CÃ i Ä‘áº·t browser
playwright install chromium
```

### Sá»­ dá»¥ng Interactive Menu
```bash
python threads_scraper_complete.py
```

Chá»n chá»©c nÄƒng:
1. **Scrape má»™t thread** - Láº¥y post vÃ  táº¥t cáº£ replies
2. **Scrape profile** - Láº¥y thÃ´ng tin user vÃ  threads gáº§n Ä‘Ã¢y
3. **So sÃ¡nh users** - So sÃ¡nh nhiá»u accounts
4. **PhÃ¢n tÃ­ch engagement** - PhÃ¢n tÃ­ch metrics chi tiáº¿t

### Sá»­ dá»¥ng trong code

```python
from threads_scraper_complete import ThreadsScraper

# Khá»Ÿi táº¡o
scraper = ThreadsScraper(headless=True)

# Scrape profile
data = scraper.scrape_user_by_username("natgeo")
print(f"Followers: {data['user']['followers']:,}")
print(f"Threads: {len(data['threads'])}")

# PhÃ¢n tÃ­ch engagement
analysis = scraper.analyze_engagement(data)
print(f"Engagement rate: {analysis['avg_engagement_rate']:.4f}%")

# LÆ°u dá»¯ liá»‡u
scraper.save_to_json(data, "natgeo.json")
scraper.save_to_excel(data, "natgeo.xlsx")

# ÄÃ³ng browser
scraper.close()
```

### Quick Examples
```bash
# Basic usage example
python threads_scraper_complete.py 2

# Analysis example
python threads_scraper_complete.py 3
```

### TÃ­nh nÄƒng
- âœ… Scrape thread (post) vá»›i replies
- âœ… Scrape user profile vá»›i threads
- âœ… So sÃ¡nh nhiá»u users
- âœ… PhÃ¢n tÃ­ch engagement (likes, engagement rate, video performance)
- âœ… Export JSON, CSV, Excel
- âœ… Retry logic vá»›i exponential backoff
- âœ… Logging chi tiáº¿t

### Use Cases
- ğŸ“Š Market research vÃ  competitor analysis
- ğŸ“ˆ Brand monitoring vÃ  sentiment tracking
- ğŸ¯ Influencer analysis
- ğŸ“± Content performance analysis
- ğŸ” Social listening

## ğŸ¦ Twitter Entertainment Crawler - NEW! ğŸ”¥

### Giá»›i thiá»‡u

Crawler chuyÃªn dá»¥ng Ä‘á»ƒ thu tháº­p dá»¯ liá»‡u Twitter/X cho bÃ i toÃ¡n **sentiment analysis trÃªn English social media comments vá» entertainment (films/music)**.

### CÃ i Ä‘áº·t

```bash
# CÃ i Ä‘áº·t snscrape
pip install snscrape

# Hoáº·c cÃ i táº¥t cáº£ dependencies
pip install -r requirements.txt
```

### TÃ­nh nÄƒng

âœ… **Scrape tweets vá» films vÃ  music**
- Tá»± Ä‘á»™ng tÃ¬m tweets vá» movies vÃ  music
- Filter chá»‰ English tweets
- Tá»± Ä‘á»™ng phÃ¢n loáº¡i film/music

âœ… **Nhiá»u cháº¿ Ä‘á»™ search**
- By keywords/hashtags
- By user
- By date range
- Film tweets riÃªng
- Music tweets riÃªng
- All entertainment tweets

âœ… **Dá»¯ liá»‡u phÃ¹ há»£p cho sentiment analysis**
- Text content (cleaned)
- Engagement metrics (likes, retweets, replies)
- Metadata (hashtags, mentions, URLs)
- Entertainment category (film/music)
- User info (verified, followers)
- Language detection (English only)

âœ… **TÃ­ch há»£p data cleaning**
- Auto-clean text
- Remove URLs, mentions (optional)
- Language detection
- Validation

### Sá»­ dá»¥ng Interactive Menu

```bash
python twitter_entertainment_crawler.py
```

**Menu options:**
1. Scrape Film Tweets
2. Scrape Music Tweets
3. Scrape All Entertainment (Film + Music)
4. Scrape by Keywords (Custom)
5. Scrape by User

### Sá»­ dá»¥ng trong Python Code

```python
from twitter_entertainment_crawler import TwitterEntertainmentCrawler

crawler = TwitterEntertainmentCrawler()

# Scrape film tweets
film_tweets = crawler.scrape_film_tweets(max_tweets=500)

# Scrape music tweets
music_tweets = crawler.scrape_music_tweets(max_tweets=500)

# Scrape by keywords
tweets = crawler.scrape_by_keywords(
    keywords=['#movie', '#film', 'movie review'],
    max_tweets=1000,
    category='film'  # or 'music'
)

# Scrape from user
tweets = crawler.scrape_by_user(
    username='netflix',
    max_tweets=200,
    category='film'
)

# Clean and save
saved_files = crawler.clean_and_save(
    tweets,
    filename="film_tweets",
    clean_data=True,
    save_format='both'  # 'csv', 'json', or 'both'
)

# Get statistics
stats = crawler.get_stats(tweets)
print(f"Total tweets: {stats['total_tweets']}")
print(f"Avg likes: {stats['avg_likes']:.1f}")
```

### Data Schema

```python
{
    'comment_id': 'tweet_id',
    'post_id': 'tweet_id',
    'platform': 'Twitter',
    'author_name': 'username',
    'author_id': 'user_id',
    'comment_text': 'tweet_content',
    'published_at': 'timestamp',
    'like_count': 'integer',
    'retweet_count': 'integer',
    'reply_count': 'integer',
    'quote_count': 'integer',
    'sentiment_label': None,  # To be filled
    'sentiment_score': None,  # To be filled
    'language': 'en',
    'entertainment_category': 'film' or 'music',
    'hashtags': 'JSON array',
    'mentions': 'JSON array',
    'urls': 'JSON array',
    'media_type': 'photo' or 'video' or None,
    'is_reply': 'boolean',
    'parent_comment_id': 'parent_tweet_id',
    'user_verified': 'boolean',
    'user_followers': 'integer',
    'tweet_id': 'tweet_id',
    'crawled_at': 'timestamp'
}
```

### Quick Test

```bash
python test_twitter_crawler.py
```

### LÆ°u Ã½

âš ï¸ **snscrape khÃ´ng cáº§n API key** - Hoáº¡t Ä‘á»™ng nhÆ° Twitter search cÃ´ng khai

âš ï¸ **Rate Limiting** - CÃ³ thá»ƒ bá»‹ rate limit náº¿u scrape quÃ¡ nhanh

âš ï¸ **Terms of Service** - TuÃ¢n thá»§ Twitter Terms of Service

âš ï¸ **Chá»‰ English** - Crawler tá»± Ä‘á»™ng filter chá»‰ English tweets

### Use Cases

- ğŸ“Š Sentiment analysis trÃªn film reviews
- ğŸµ Sentiment analysis trÃªn music discussions
- ğŸ“ˆ Track public opinion vá» movies/music
- ğŸ” Research entertainment industry trends
- ğŸ’¬ Analyze user engagement vá»›i entertainment content

## ğŸ“„ License

MIT License - Xem file LICENSE Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.

## ğŸ“ LiÃªn há»‡

- **Email**: your-email@example.com
- **GitHub**: [your-github-username](https://github.com/your-username)

---

**LÆ°u Ã½**: Dá»± Ã¡n nÃ y chá»‰ dÃ nh cho má»¥c Ä‘Ã­ch há»c táº­p vÃ  nghiÃªn cá»©u. Vui lÃ²ng tuÃ¢n thá»§ Terms of Service cá»§a cÃ¡c ná»n táº£ng máº¡ng xÃ£ há»™i.
