"""
Script lÃ m sáº¡ch vÃ  chuáº©n hÃ³a dá»¯ liá»‡u comments
"""

import re
import pandas as pd
import numpy as np
from typing import List, Dict, Optional
import logging
from datetime import datetime

# Thiáº¿t láº­p logging
from logger_config import get_cleaner_logger
logger = get_cleaner_logger()

class CommentDataCleaner:
    def __init__(self):
        """
        Khá»Ÿi táº¡o Comment Data Cleaner
        """
        # Regex patterns Ä‘á»ƒ lÃ m sáº¡ch text
        self.url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')
        self.mention_pattern = re.compile(r'@\w+')
        self.hashtag_pattern = re.compile(r'#\w+')
        self.emoji_pattern = re.compile(r'[^\w\s.,!?;:()\-]')
        self.extra_spaces_pattern = re.compile(r'\s+')
        
        # Danh sÃ¡ch tá»« ngá»¯ khÃ´ng mong muá»‘n
        self.stop_words = {
            'en': ['the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'can', 'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them'],
            'vi': ['vÃ ', 'cá»§a', 'vá»›i', 'tá»«', 'trong', 'trÃªn', 'dÆ°á»›i', 'vá»', 'cho', 'Ä‘á»ƒ', 'khi', 'náº¿u', 'nhÆ°ng', 'hoáº·c', 'lÃ ', 'cÃ³', 'Ä‘Æ°á»£c', 'sáº½', 'Ä‘Ã£', 'Ä‘ang', 'tÃ´i', 'báº¡n', 'anh', 'chá»‹', 'em', 'chÃºng', 'há»', 'nÃ y', 'Ä‘Ã³', 'kia', 'Ä‘Ã¢y', 'Ä‘Ã³']
        }
    
    def clean_comment_text(self, text: str, remove_urls: bool = True, 
                          remove_mentions: bool = True, remove_hashtags: bool = True,
                          remove_emojis: bool = False, normalize_spaces: bool = True) -> str:
        """
        LÃ m sáº¡ch text comment
        
        Args:
            text (str): Text gá»‘c
            remove_urls (bool): CÃ³ xÃ³a URLs khÃ´ng
            remove_mentions (bool): CÃ³ xÃ³a mentions (@username) khÃ´ng
            remove_hashtags (bool): CÃ³ xÃ³a hashtags (#tag) khÃ´ng
            remove_emojis (bool): CÃ³ xÃ³a emojis khÃ´ng
            normalize_spaces (bool): CÃ³ chuáº©n hÃ³a khoáº£ng tráº¯ng khÃ´ng
            
        Returns:
            str: Text Ä‘Ã£ Ä‘Æ°á»£c lÃ m sáº¡ch
        """
        if not text or pd.isna(text):
            return ""
        
        # Chuyá»ƒn vá» string vÃ  loáº¡i bá» khoáº£ng tráº¯ng Ä‘áº§u cuá»‘i
        text = str(text).strip()
        
        # XÃ³a URLs
        if remove_urls:
            text = self.url_pattern.sub('', text)
        
        # XÃ³a mentions
        if remove_mentions:
            text = self.mention_pattern.sub('', text)
        
        # XÃ³a hashtags
        if remove_hashtags:
            text = self.hashtag_pattern.sub('', text)
        
        # XÃ³a emojis (tÃ¹y chá»n)
        if remove_emojis:
            text = self.emoji_pattern.sub('', text)
        
        # Chuáº©n hÃ³a khoáº£ng tráº¯ng
        if normalize_spaces:
            text = self.extra_spaces_pattern.sub(' ', text)
        
        return text.strip()
    
    def detect_language(self, text: str) -> str:
        """
        PhÃ¡t hiá»‡n ngÃ´n ngá»¯ cá»§a comment (Ä‘Æ¡n giáº£n)
        
        Args:
            text (str): Text comment
            
        Returns:
            str: 'vi' (tiáº¿ng Viá»‡t) hoáº·c 'en' (tiáº¿ng Anh)
        """
        if not text:
            return 'unknown'
        
        # Äáº¿m kÃ½ tá»± tiáº¿ng Viá»‡t
        vietnamese_chars = len(re.findall(r'[Ã Ã¡áº¡áº£Ã£Ã¢áº§áº¥áº­áº©áº«Äƒáº±áº¯áº·áº³áºµÃ¨Ã©áº¹áº»áº½Ãªá»áº¿á»‡á»ƒá»…Ã¬Ã­á»‹á»‰Ä©Ã²Ã³á»á»ÃµÃ´á»“á»‘á»™á»•á»—Æ¡á»á»›á»£á»Ÿá»¡Ã¹Ãºá»¥á»§Å©Æ°á»«á»©á»±á»­á»¯á»³Ã½á»µá»·á»¹Ä‘]', text.lower()))
        
        # Äáº¿m tá»« tiáº¿ng Viá»‡t phá»• biáº¿n
        vietnamese_words = ['vÃ ', 'cá»§a', 'vá»›i', 'tá»«', 'trong', 'trÃªn', 'dÆ°á»›i', 'vá»', 'cho', 'Ä‘á»ƒ', 'khi', 'náº¿u', 'nhÆ°ng', 'hoáº·c', 'lÃ ', 'cÃ³', 'Ä‘Æ°á»£c', 'sáº½', 'Ä‘Ã£', 'Ä‘ang']
        vietnamese_word_count = sum(1 for word in vietnamese_words if word in text.lower())
        
        # Náº¿u cÃ³ nhiá»u kÃ½ tá»± tiáº¿ng Viá»‡t hoáº·c tá»« tiáº¿ng Viá»‡t
        if vietnamese_chars > 2 or vietnamese_word_count > 0:
            return 'vi'
        else:
            return 'en'
    
    def remove_stop_words(self, text: str, language: str = 'auto') -> str:
        """
        Loáº¡i bá» stop words
        
        Args:
            text (str): Text gá»‘c
            language (str): NgÃ´n ngá»¯ ('vi', 'en', 'auto')
            
        Returns:
            str: Text Ä‘Ã£ loáº¡i bá» stop words
        """
        if not text:
            return ""
        
        # Tá»± Ä‘á»™ng phÃ¡t hiá»‡n ngÃ´n ngá»¯
        if language == 'auto':
            language = self.detect_language(text)
        
        if language not in self.stop_words:
            return text
        
        words = text.lower().split()
        filtered_words = [word for word in words if word not in self.stop_words[language]]
        
        return ' '.join(filtered_words)
    
    def validate_comment(self, comment: Dict) -> Dict:
        """
        Kiá»ƒm tra vÃ  validate comment data
        
        Args:
            comment (Dict): Comment data
            
        Returns:
            Dict: Comment Ä‘Ã£ Ä‘Æ°á»£c validate vÃ  lÃ m sáº¡ch
        """
        cleaned_comment = comment.copy()
        
        # LÃ m sáº¡ch comment text
        original_text = comment.get('comment_text', '')
        cleaned_text = self.clean_comment_text(original_text)
        
        # PhÃ¡t hiá»‡n ngÃ´n ngá»¯
        language = self.detect_language(cleaned_text)
        
        # Loáº¡i bá» stop words
        text_without_stopwords = self.remove_stop_words(cleaned_text, language)
        
        # Cáº­p nháº­t comment
        cleaned_comment.update({
            'comment_text': cleaned_text,
            'comment_text_clean': text_without_stopwords,
            'language': language,
            'text_length': len(cleaned_text),
            'word_count': len(cleaned_text.split()),
            'is_valid': len(cleaned_text.strip()) > 0,
            'cleaned_at': datetime.now().isoformat()
        })
        
        # Validate cÃ¡c trÆ°á»ng khÃ¡c
        cleaned_comment['like_count'] = max(0, int(comment.get('like_count', 0)))
        cleaned_comment['reply_count'] = max(0, int(comment.get('reply_count', 0)))
        
        return cleaned_comment
    
    def clean_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        LÃ m sáº¡ch toÃ n bá»™ DataFrame
        
        Args:
            df (pd.DataFrame): DataFrame chá»©a comments
            
        Returns:
            pd.DataFrame: DataFrame Ä‘Ã£ Ä‘Æ°á»£c lÃ m sáº¡ch
        """
        logger.info(f"Báº¯t Ä‘áº§u lÃ m sáº¡ch {len(df)} comments...")
        
        # Táº¡o báº£n copy Ä‘á»ƒ khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n data gá»‘c
        cleaned_df = df.copy()
        
        # LÃ m sáº¡ch tá»«ng comment
        cleaned_comments = []
        for idx, comment in df.iterrows():
            try:
                cleaned_comment = self.validate_comment(comment.to_dict())
                cleaned_comments.append(cleaned_comment)
            except Exception as e:
                logger.warning(f"Lá»—i khi lÃ m sáº¡ch comment {idx}: {e}")
                # Giá»¯ nguyÃªn comment gá»‘c náº¿u cÃ³ lá»—i
                cleaned_comments.append(comment.to_dict())
        
        # Táº¡o DataFrame má»›i
        result_df = pd.DataFrame(cleaned_comments)
        
        # Thá»‘ng kÃª
        valid_comments = result_df[result_df['is_valid'] == True]
        logger.info(f"HoÃ n thÃ nh lÃ m sáº¡ch:")
        logger.info(f"  - Comments há»£p lá»‡: {len(valid_comments)}/{len(result_df)}")
        logger.info(f"  - Tiáº¿ng Viá»‡t: {len(result_df[result_df['language'] == 'vi'])}")
        logger.info(f"  - Tiáº¿ng Anh: {len(result_df[result_df['language'] == 'en'])}")
        
        return result_df
    
    def get_cleaning_stats(self, df: pd.DataFrame) -> Dict:
        """
        Láº¥y thá»‘ng kÃª vá» quÃ¡ trÃ¬nh lÃ m sáº¡ch
        
        Args:
            df (pd.DataFrame): DataFrame Ä‘Ã£ lÃ m sáº¡ch
            
        Returns:
            Dict: Thá»‘ng kÃª
        """
        stats = {
            'total_comments': len(df),
            'valid_comments': len(df[df['is_valid'] == True]),
            'invalid_comments': len(df[df['is_valid'] == False]),
            'language_distribution': df['language'].value_counts().to_dict(),
            'avg_text_length': df['text_length'].mean(),
            'avg_word_count': df['word_count'].mean(),
            'platform_distribution': df['platform'].value_counts().to_dict() if 'platform' in df.columns else {},
            'date_range': {
                'earliest': df['published_at'].min() if 'published_at' in df.columns else None,
                'latest': df['published_at'].max() if 'published_at' in df.columns else None
            }
        }
        
        return stats


def main():
    """
    HÃ m main Ä‘á»ƒ test data cleaner
    """
    print("=== TEST DATA CLEANER ===\n")
    
    # Táº¡o sample data Ä‘á»ƒ test
    sample_comments = [
        {
            'comment_id': '1',
            'comment_text': 'Video nÃ y hay quÃ¡! ğŸ‘ğŸ‘ğŸ‘ @username #trending https://example.com',
            'author_name': 'User1',
            'like_count': 5,
            'platform': 'YouTube'
        },
        {
            'comment_id': '2', 
            'comment_text': 'This is amazing! Love it so much â¤ï¸â¤ï¸â¤ï¸',
            'author_name': 'User2',
            'like_count': 10,
            'platform': 'YouTube'
        },
        {
            'comment_id': '3',
            'comment_text': 'TÃ´i ráº¥t thÃ­ch video nÃ y, cáº£m Æ¡n báº¡n Ä‘Ã£ chia sáº»!',
            'author_name': 'User3',
            'like_count': 3,
            'platform': 'YouTube'
        },
        {
            'comment_id': '4',
            'comment_text': '',  # Comment rá»—ng
            'author_name': 'User4',
            'like_count': 0,
            'platform': 'YouTube'
        }
    ]
    
    # Táº¡o DataFrame
    df = pd.DataFrame(sample_comments)
    print("ğŸ“ Sample data:")
    print(df[['comment_text', 'author_name', 'like_count']].to_string())
    
    # Khá»Ÿi táº¡o cleaner
    cleaner = CommentDataCleaner()
    
    # LÃ m sáº¡ch data
    print(f"\nğŸ”„ Äang lÃ m sáº¡ch data...")
    cleaned_df = cleaner.clean_dataframe(df)
    
    # Hiá»ƒn thá»‹ káº¿t quáº£
    print(f"\nâœ… Káº¿t quáº£ sau khi lÃ m sáº¡ch:")
    print(cleaned_df[['comment_text', 'comment_text_clean', 'language', 'is_valid', 'text_length']].to_string())
    
    # Thá»‘ng kÃª
    stats = cleaner.get_cleaning_stats(cleaned_df)
    print(f"\nğŸ“Š Thá»‘ng kÃª:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # Test cÃ¡c hÃ m riÃªng láº»
    print(f"\nğŸ§ª Test cÃ¡c hÃ m riÃªng láº»:")
    
    test_text = "Video nÃ y hay quÃ¡! ğŸ‘ğŸ‘ğŸ‘ @username #trending https://example.com"
    print(f"Text gá»‘c: {test_text}")
    
    # Test clean_comment_text
    cleaned = cleaner.clean_comment_text(test_text)
    print(f"Sau khi lÃ m sáº¡ch: {cleaned}")
    
    # Test detect_language
    language = cleaner.detect_language(cleaned)
    print(f"NgÃ´n ngá»¯: {language}")
    
    # Test remove_stop_words
    without_stopwords = cleaner.remove_stop_words(cleaned, language)
    print(f"KhÃ´ng stop words: {without_stopwords}")


if __name__ == "__main__":
    main()
